version: "1.0"
description: Data transformation to generate daily average data from original GLDAS data sources
inputs:
  gldas_dataset_id:
    comment: DataCatalog Dataset ID for GLDAS
    value: {INPUTS1}
  shapefile_dataset_id:
    comment: DataCatalog Dataset ID for Shapefile with woredas
    value: {INPUTS2}
  agg_function:
    comment: Operation to be used for aggregation. Values can be ("sum", "average", "count")
    value: {PARAMS1}
  agg_time_period:
    comment: Time period for aggregation. Values can be ("minute", "hour", "day", "month", "year")
    value: {PARAMS2}
  range_start_time:
    comment: Start time to filter Resources for DataCatalog GLDAS Dataset ("YYYY-MM-DD HH:MM:SS" format or "null" to leave this end open)
    value: {PARAMS3}
  range_end_time:
    comment: End time to filter Resources for DataCatalog GLDAS Dataset ("YYYY-MM-DD HH:MM:SS" format or "null" to leave this end open)
    value: {PARAMS4}
  range_step_time:
    comment: >-
      ISO 8601 duration string representing the step (or timedelta) to loop from range_start_time to range_end_time.
      Value should be such that agg_time_period lies completely in it. Typically should just be ("P1D", "P1M", "P1Y").
      "P1D" should be used with agg_time_period ("minute", "hour", "day"), "P1M" with ("month") and "P1Y" with ("year").
    value: {PARAMS5}
  csv_output_file:
    comment: Filename for output CSV
    value: {OUTPUTS1}
adapters:
  gldas_range_stream:
    comment: My gldas range stream adapter
    adapter: funcs.DcatRangeStream
    inputs:
      dataset_id: $$.gldas_dataset_id  
      start_time: $$.range_start_time
      end_time: $$.range_end_time
      step_time: $$.range_step_time
  gldas_read_func:
    comment: My gldas read func adapter
    adapter: funcs.DcatReadFunc
    inputs:
      dataset_id: $$.gldas_dataset_id
      start_time: $.gldas_range_stream.start_time
      end_time: $.gldas_range_stream.end_time
  shapefile_read_func:
    comment: My shape file read func adapter
    adapter: funcs.DcatReadFunc
    inputs:
      dataset_id: $$.shapefile_dataset_id
  gldas_variable_stream:
    comment: My gldas variables stream adapter
    adapter: funcs.DcatVariableStream
    inputs:
      dataset_id: $$.gldas_dataset_id
  my_crop_wrapper:
    comment: My cropping func wrapper adapter
    adapter: funcs.CroppingTransWrapper
    inputs:
      variable_name: $.gldas_variable_stream.variable_name
      dataset: $.gldas_read_func.data
      shape: $.shapefile_read_func.data
  agg_by_time_place:
    adapter: funcs.aggregations.variable_aggregation_func.VariableAggregationFunc
    inputs:
      dataset: $.my_crop_wrapper.data
      group_by:
        - { prop: "mint:timestamp", value: $$.agg_time_period }
        - { prop: "mint:place", value: exact }
      function: $$.agg_function
  my_writer:
    adapter: funcs.CSVWriteFunc
    inputs:
      data: $.agg_by_time_place.data
      output_file: $$.csv_output_file
