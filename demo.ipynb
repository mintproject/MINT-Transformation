{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ujson, csv, time\n",
    "from dtran import Pipeline, IFunc, ArgType\n",
    "from funcs import ReadFunc, GraphWriteFunc, UnitTransFunc\n",
    "from drepr import Graph\n",
    "\n",
    "DEMO_CSV_INPUT_FILE = \"./examples/demo/s01_ethiopia_commodity_price.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a demo with an example flow for the MINT transformation pipeline\n",
    "\n",
    "This notebook presents an abstraction of the MINT Data Transformations architecture and walks thourgh an example through the pipeline we are suggesting; we show a simple CSV --(unit transformations)--> CSV flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install scipy\n",
    "# independent from transformation code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Indicator Code              IndicatorName   Unit Frequency     Date  Value\n",
      "0    CRUDE_PETRO  Crude oil, average($/bbl)  $/bbl         M  1960M01   1.63\n",
      "1    CRUDE_PETRO  Crude oil, average($/bbl)  $/bbl         M  1960M02   1.63\n",
      "2    CRUDE_PETRO  Crude oil, average($/bbl)  $/bbl         M  1960M03   1.63\n",
      "3    CRUDE_PETRO  Crude oil, average($/bbl)  $/bbl         M  1960M04   1.63\n",
      "4    CRUDE_PETRO  Crude oil, average($/bbl)  $/bbl         M  1960M05   1.63\n"
     ]
    }
   ],
   "source": [
    "# show first 5 rows of the input demo file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(DEMO_CSV_INPUT_FILE)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Semantic) Description of a component (reader/writer/transformation functions)\n",
    "\n",
    "Providing semantic description of a function may allow constructing the pipeline semi-automatically. There are two levels of a semantic description:\n",
    "\n",
    "1. Providing definition for inputs/outputs of a component: it enables input data validation and compatibility checking between connected components.\n",
    "2. Providing definition of the purpose of the component: it allows us to construct the transformation pipeline based on some specification from users\n",
    "\n",
    "```python\n",
    "class IFunc(abc.ABC):\n",
    "    id: str = \"\"\n",
    "        \n",
    "    # level 2\n",
    "    description = None\n",
    "    \n",
    "    # level 1\n",
    "    inputs: Dict[str, ArgType] = {}\n",
    "    outputs: Dict[str, ArgType] = {}\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def validate(self) -> bool:\n",
    "        \"\"\"\n",
    "        Check if the inputs are correct or not\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @abc.abstractmethod\n",
    "    def exec(self) -> dict:\n",
    "        \"\"\"\n",
    "        Execute the transformation function and return the result\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the semantic description of the interface (control plane) between all of the components in the pipeline (Reader/Writer/Transformation Adapters)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here's an example flow:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 1: Reader Adapter\n",
    "\n",
    "An instance of a reader adapter can be used as an entry point in the pipeline. It reads an input file `input.csv` file and a `input.yaml` file describing the D-REPR layout of this file. The data are representated in general way in a python object (Graph or NumPY array) and will be used in the next steps in the pipeline.\n",
    "\n",
    "```python\n",
    "class ReadFunc(IFunc):\n",
    "    id = \"read_func\"\n",
    "    inputs = {\n",
    "        \"repr_file\": ArgType.FilePath, \n",
    "        \"resources\": ArgType.String\n",
    "    }\n",
    "    outputs = {\"data\": ArgType.Graph(None)}\n",
    "    \n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 2: Transformation Adapter\n",
    "\n",
    "An instance of a transformation adapter does not materialize the data into an output, it just reproduces the data, transformaing its content (the actual data) and performing the needed configrations in the 'control plane' parameters.\n",
    "Given the pythonic object (graph) representing the data and the rest of the needed configurations in the calling API ('control plane' parameters) we can re-construct the data in a new pythonic object (graph) and prepare it for the next steps in the pipeline.\n",
    "\n",
    "```python\n",
    "class TransFunc(IFunc):\n",
    "    id = \"trans_func\"\n",
    "    inputs = {\"graph\": ArgType.Graph(None)}\n",
    "    outputs = {\"graph\": ArgType.Graph(None)}\n",
    "    \n",
    "    def __init__(self, graph: Graph):\n",
    "        self.graph = graph\n",
    "        \n",
    "    def exec(self):\n",
    "        for node in self.graph.nodes:\n",
    "            # do something for each node\n",
    "        return {\n",
    "            \"graph\": self.graph\n",
    "        }\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component 3: Writer Adapter\n",
    "\n",
    "An instance of a writer adapter can be used as an exit point in the pipeline. It writes an output file `output.csv` based on a given `output.yaml` (D-REPR layout) and an additional configuration file `output.config`\n",
    "\n",
    "```python\n",
    "class WriteFuncGraph(IFunc):\n",
    "    id = \"write_func_graph\"\n",
    "    inputs = {\"graph\": ArgType.Graph(None), \"repr_file\": ArgType.FilePath, \"main_class\": ArgType.String}\n",
    "    outputs = {\"resources\": ArgType.String}\n",
    "\n",
    "    def __init__(self, graph: Graph, repr_file: str, main_class: str):\n",
    "        self.graph = graph\n",
    "        self.main_class = main_class\n",
    "\n",
    "        self.repr = Repr.from_file(repr_file)\n",
    "\n",
    "    def exec(self) -> dict:\n",
    "        all_data_rows = []\n",
    "        for rid, resource in self.repr.iter_resources():\n",
    "            if resource[\"type\"] == \"csv\":\n",
    "                all_data_rows = self.tabularize_data()\n",
    "                self._dump_to_csv(all_data_rows)\n",
    "            elif resource[\"type\"] == \"json\":\n",
    "                all_data_rows = self.tabularize_data()\n",
    "                self._dump_to_json(all_data_rows)\n",
    "        return {\"data\": all_data_rows}\n",
    "    ...\n",
    "\n",
    "```\n",
    "\n",
    "Main idea for generalizing writers: \n",
    "- Implement a random indexer for each file type. \n",
    "- Design a configuration file to specify dimensional mapping between different attributes \n",
    "    1. extend Binh's representation file\n",
    "    2. redesign a new configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected object or value",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b47885562b71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mUnitTransFunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mO\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGraphWriteFunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m ])\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/ws/dtran/pipeline.py\u001b[0m in \u001b[0;36mexec\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0margname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunc_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/ws/funcs/readers/read_func.py\u001b[0m in \u001b[0;36mexec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_drepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresources\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/drepr/graph.py\u001b[0m in \u001b[0;36mfrom_drepr\u001b[0;34m(ds_model, resources)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mser_node\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser_nodes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mujson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mser_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected object or value"
     ]
    }
   ],
   "source": [
    "DEMO_CSV_OUTPUT_FILE = \"./examples/demo/s01_ethiopia_commodity_price_write.csv\"\n",
    "\n",
    "inputs = {\n",
    "    \"read_func__1__repr_file\": \"./examples/demo/s01_ethiopia_commodity_price.yml\",\n",
    "    \"read_func__1__resources\": DEMO_CSV_INPUT_FILE,\n",
    "    \"unit_trans__1__unit_value\": \"rdf:value\",\n",
    "    \"unit_trans__1__unit_label\": \"eg:unit\",\n",
    "    \"unit_trans__1__unit_desired\": \"$/liter\",\n",
    "    \"graph_write_func__1__main_class\": \"qb:Observation\",\n",
    "    \"graph_write_func__1__output_file\": DEMO_CSV_OUTPUT_FILE,\n",
    "    \"graph_write_func__1__mapped_columns\": {}\n",
    "}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ReadFunc,\n",
    "    UnitTransFunc,\n",
    "    GraphWriteFunc\n",
    "], wired=[\n",
    "    ReadFunc.O.data == UnitTransFunc.I.graph,\n",
    "    UnitTransFunc.O.graph == GraphWriteFunc.I.graph\n",
    "])\n",
    "outputs = pipeline.exec(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show first 5 rows of the output demo file\n",
    "import pandas as pd\n",
    "df = pd.read_csv(DEMO_CSV_OUTPUT_FILE)\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
